\section{Video Compression}
\label{sec:introduction/section_b}

The early form of video compression is described by Ray Davis Kell in 1929 as the difficulty of transmitting the whole successive images of video can be avoided by only sending the difference between the successive images, though it was not actually used; however, it became the foundation for the video compression standards today \cite{jacobs_brief_2009}. The early video compression was the analog system but the digital video processing has been developed and is widely used today. \citeauthor{zhang_overview_2019} explained the concept of typical video compression nowadays as following \cite{zhang_overview_2019}. The video compression consists of the encoder compressing the images into the compressed form, which can be stored or transmitted to the other location, and the decoder to decompress the images. This process of coding and decoding is also called a codec. The typical video compression standards nowadays comprise predictive coding, transform coding, and entropy coding, as shown in Figure \ref{fig:comp_architecture}. Predictive coding is the component that reduces the inter-frame temporal redundancy and intra-frame spatial redundancy in a video by motion estimation (ME) and motion compensation (MC) techniques. Transform coding is the component where the quantized transform coefficients are generated through discrete cosine transforms (DCT) to help reduce the spatial dependencies. Entropy coding is the component where compressed bitstreams are generated.

\input{tex/figures/comp_architecture}

There are two types of video coding; lossless coding and lossy coding. Lossless coding compresses the images and obtains the reconstructed images after decompression without any loss of information. Lossy coding, however, compresses the images by removing the less important information, which will sacrifice the image quality to the level the human visual system can tolerate. Lossy compression is more widely used today since it allows a much smaller compressed size and more efficient than the lossless manner.

Since the first video compression standard of H.120 developed in 1984, various video compression standards have been developed, such as MPEG and H.26X series \cite{zhang_overview_2019}. The organization of Moving Picture Experts Group (MPEG) in the International Standards Organization (ISO) and the International Electrotechnical Commission (IEC) are developing the MPEG series such as MPEG-1, MPEG-2, and MPEG-4.

The Video Coding Expert Group (VCEG) organization of International Telecommunication Union (ITU-T) is developing H.26X series starting from the first standard of H.120. They then developed H.261, H.262, H.263, H.264 (AVC), and H.265 (HEVC). H.264, so-called Advanced Video Coding (AVC), was developed in 2003, and the typical architecture shown in Figure \ref{fig:comp_architecture} were followed since H.264/AVC. H.264/AVC is the most widely used standard nowadays and supports up to 4k resolution of video. H.265, so-called High Efficiency Video Coding (HEVC), was developed based on H.264/AVC structure and is a more recent standard that has been developed in 2013. H.265/HEVC supports the up to 8k resolution of the video but is not yet widely supported. There has been more recent development of standards such as, for example, Versatile Video Coding (VVC) and AOMedia Video 1 (AV1). These newly developed standards, after the predecessor of H.265/HEVC, achieve better coding performance and will allow high quality and efficiency, VR system, and 360-degree video applications. However, these standards and H.265/HEVC are still yet to be supported due to the hardware's lack of current computational power. As a possible future generation of video compression standards after VVC and AV1, there has been research in compression technologies, utilizing machine learning for video coding, hardware acceleration, and parallel computing. Out of these video compression standards, we have adopted H.265/HEVC for the experiment in this thesis.