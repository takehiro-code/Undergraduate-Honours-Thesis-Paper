\section{High Efficiency Video Coding (HEVC)}
\label{sec:background/section_c}

H.265/HEVC is the video compression standard developed by ITU-T Video Coding Expert Group in 2013. H.265/HEVC follows the same structure of its predecessor H.264/AVC as shown in the Fig.\ref{fig:comp_architecture} but achieves a better coding performance. The typical structure consists of predictive coding with intra-frame and inter-frame prediction, transform coding that generates the quantized transform coefficients from DCT, and finally the entropy coding that generates a compressed bitstream. To obtain the de-compressed video, HEVC performs entropy decoding, transform decoding, and predictive decoding, which is in a reversed order to the encoding part \cite{zhang_overview_2019}. For the experiment, we have used the lossy compression of HEVC test model (HM) at version 16.20, and selected two parameters of compresson settings varied for the experiment; quantization parameter and motion search range.

\subsection{Quantization Parameter}
Quantization parameter (QP) is the parameter used in the transform coding. The value of QP determines the quantization step size by which we obtain the quantized transform matrix. QP ranges from 0 to 51 and an increase of 6 in QP will double the quantization step size \cite{sullivan_overview_2012} \cite{budagavi_hevc_2014}. According to \cite{sharrab_modeling_2017}, QP has a significant impact on bitrate. They showed that bitrate is inversely proportional to QP and the pixel rate is linear proportional to the pixel rate. This means that high QP will result in lower bitrate and hence lower pixel rate. In other words, high QP will cause resolution to be lower while low QP will sustain high resolution.

\subsection{Motion Search Range}
Motion estimation is inter-frame prediction technique that finds the best match of the block of regions between the previous reference frame and the current frame while minimizing the rate-distortion cost or highest correlation. Motion estimation is essentially reducing the temporal redundancies by obtaining a motion vector that points from the region in the previous reference frame toward the target candidate region in the current frame. This block of region is search window and its size is considered as search range (SR). The high SR value uses a larger search window and hence requires more memory in bandwidth but low SR uses a smaller search window and requires less memory  \cite{lou_adaptive_2010} \cite{bachu_review_2015}. From this logic, we can interpret that the large search window could cover fast motion in a video with SR high enough, while the low SR only covers the slower motion. In the experiment, we label the parameter as motion search range (MSR).

